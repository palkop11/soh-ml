{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8DQfl6bJE0oKN5zLDB/eM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palkop11/soh-ml/blob/master/interaction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparations"
      ],
      "metadata": {
        "id": "kHXr0-V8JUh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount\n",
        "Mount google drive so you can upload DATA from drive to colab environment"
      ],
      "metadata": {
        "id": "mCJDkSMtJGCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HGH2LzsgLfrt",
        "outputId": "24839076-6d26-4b23-b956-1d756715255c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone, change directory\n",
        "Clone repository (works when repo is public), then jump to repo directory"
      ],
      "metadata": {
        "id": "glUVc1VEJaIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocPUyEzsHWKh",
        "outputId": "b6244e42-8962-4437-8f3a-539dbf728b43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'soh-ml' already exists and is not an empty directory.\n",
            "/content/soh-ml\n"
          ]
        }
      ],
      "source": [
        "# clone repo\n",
        "!git clone https://github.com/palkop11/soh-ml.git\n",
        "\n",
        "# jump to repo directory\n",
        "%cd soh-ml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload dataset\n",
        "Before running cell below, make sure that 'dataset_v5_ts_npz.zip' was uploaded anywhere in your drive, and drive was mounted. \\\n",
        "Find archive and extract into content/soh-ml/DATA :"
      ],
      "metadata": {
        "id": "cl2Ubu0nJv09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find \"datset_v5_ts_npz.zip\" and then extract it into temporary workspace\n",
        "!find /content/drive -name \"dataset_v5_ts_npz.zip\" | xargs -I {} unzip -qo {} -d \"./DATA/\"\n",
        "# check if dataset directory was created\n",
        "!find /content/soh-ml/DATA -maxdepth 1"
      ],
      "metadata": {
        "id": "5wJNGzC-Aq1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7ab97d-3653-4b84-c6c7-792fba7c5e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/soh-ml/DATA\n",
            "/content/soh-ml/DATA/dataset_v5_ts_npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs, imports, fix seed"
      ],
      "metadata": {
        "id": "ghJT75xPK-0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run cell below to install packages"
      ],
      "metadata": {
        "id": "4jEk3v6ULUdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "here should be pip install from requirements_colab for reproducibility\n",
        "but now it results in errors :/\n",
        "!pip install -r requirements_colab.txt -q\n",
        "\"\"\"\n",
        "\n",
        "!pip install tensorboard tbparse pytorch-lightning lightning -q"
      ],
      "metadata": {
        "id": "fBb_4rjuOYqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make sure that you are in project directory content/soh-ml, otherwise some imports will fail"
      ],
      "metadata": {
        "id": "JJPxJvmRLVnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/soh-ml/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGlZz2xQ34jX",
        "outputId": "4701b65e-0971-404e-b499-dafcd60e930b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/soh-ml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "make imports, fix seed"
      ],
      "metadata": {
        "id": "hiaWRQpVLo8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import learning\n",
        "import cross_validation\n",
        "\n",
        "from lightning import seed_everything\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX75gBYmx6az",
        "outputId": "11282c46-ef10-4eff-f038-619b5e70db0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running experiments"
      ],
      "metadata": {
        "id": "jEU6KZi7Lt41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## how to run single experiment"
      ],
      "metadata": {
        "id": "yxEI0g1zROkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "you can use run_experiment function from learning.py to run experiment. \\\n",
        "This will run experiment with default testing configuration:\n",
        "```python\n",
        "learning.run_experiment(learning.test_config)\n",
        "```\n",
        "Also, you can run it from command line. Without arguments it will run with test_config configuration:\n",
        "```bash\n",
        "!python learning.py\n",
        "```"
      ],
      "metadata": {
        "id": "vBvwqog7LzHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run experiment with your own config, you can specify it using python code and then pass config dictionary as argument to run_experiment function:\n",
        "```python\n",
        "# all keys (except ['test'] in ['data'])\n",
        "# shoud be present in this single experiment configure dictionary:\n",
        "my_config = {\n",
        "    'experiment_name': 'my_experiment', # also used for TensorBoard logging\n",
        "    'seed': 42,\n",
        "\n",
        "    'data': {\n",
        "        'datadir':'./DATA/dataset_v5_ts_npz/',\n",
        "        # 'supported subsets as string arguments:\n",
        "        # 'blacklist', 'small', 'train', 'val', 'test'\n",
        "        # or you can specify subset using list with battery IDs\n",
        "        'train': 'train',\n",
        "        'val': 'val',\n",
        "        #'test': None # normally, you dont need to specify test dataset\n",
        "        # supported normalization types:\n",
        "        # 'minmax_zero_one', 'minmax_symmetric', 'meanimax', 'meanstd'\n",
        "        'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "        'n_diff': 0,\n",
        "    },\n",
        "\n",
        "    'model': {\n",
        "        'input_size': 2,\n",
        "        'cnn_hidden_dim': 32,\n",
        "        'cnn_channels': [4, 8, 16],\n",
        "        'lstm_hidden_size': 32,\n",
        "        'num_layers': 1,\n",
        "        'output_size': 1, # do not change that\n",
        "        'dropout': 0.,\n",
        "        'regressor_hidden_dim': 1024,\n",
        "        'output_activation': 'sigmoid', # 'tanh', 'sigmoid', 'relu' are supported\n",
        "    },\n",
        "\n",
        "    'training': {\n",
        "        'resume_ckpt': None,\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 1e-3,\n",
        "        'loss_type': 'huber', # 'mse', 'huber', 'bce' are supported\n",
        "        'epochs': 1,\n",
        "        'accelerator': 'auto',\n",
        "        'devices': 1,\n",
        "    },\n",
        "\n",
        "    'metrics': 'all', # 'all', 'mse', 'mae', 'mape', 'r2', 'pcc' are supported\n",
        "\n",
        "    'logging': {\n",
        "        'log_dir': './LOGS',\n",
        "        'progress_bar': True,\n",
        "    }\n",
        "```\n",
        "and then run experiment just like this:\n",
        "```python\n",
        "learning.run_experiment(my_config)\n",
        "```\n",
        "also, such config may be stored in .yaml format and then you can pass it to run_experiment:\n",
        "```python\n",
        "learning.run_experiment('path/to/my/config/my_config.yaml')\n",
        "```\n",
        "also you can specify config when running learning.py in command line:\n",
        "```bash\n",
        "!python learning.py --config path/to/my/config.yaml\n",
        "```"
      ],
      "metadata": {
        "id": "E6hrPk70Nkjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "during experiment, inside LOGS directory (or any other 'log_dir', which you will specify in config) \\\n",
        "would be created directory for each experiment and version: \\\n",
        "my_experiment/version_0"
      ],
      "metadata": {
        "id": "iV5BGQOsSQ7b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r_ESXU3jSoDa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}