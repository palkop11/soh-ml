{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD5/ph8xkuzYnRnu+d/mUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palkop11/soh-ml/blob/master/interaction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparations"
      ],
      "metadata": {
        "id": "kHXr0-V8JUh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount\n",
        "Mount google drive so you can upload DATA from drive to colab environment"
      ],
      "metadata": {
        "id": "mCJDkSMtJGCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HGH2LzsgLfrt",
        "outputId": "9dc46bd7-bd52-43df-a80f-6ba11687ed3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone, change directory\n",
        "Clone repository (works when repo is public), then jump to repo directory"
      ],
      "metadata": {
        "id": "glUVc1VEJaIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocPUyEzsHWKh",
        "outputId": "9441f000-6972-481f-ee8f-1ad2e79465dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'soh-ml' already exists and is not an empty directory.\n",
            "/content/soh-ml\n"
          ]
        }
      ],
      "source": [
        "# clone repo\n",
        "!git clone https://github.com/palkop11/soh-ml.git\n",
        "\n",
        "# jump to repo directory\n",
        "%cd soh-ml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload dataset\n",
        "Before running cell below, make sure that 'dataset_v5_ts_npz.zip' was uploaded anywhere in your drive, and drive was mounted. \\\n",
        "Find archive and extract into content/soh-ml/DATA :"
      ],
      "metadata": {
        "id": "cl2Ubu0nJv09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find \"dataset_v5_ts_npz.zip\" and then extract it into temporary workspace\n",
        "!find /content/drive -name \"dataset_v5_ts_npz.zip\" | xargs -I {} unzip -qo {} -d \"./DATA/\"\n",
        "# check if dataset directory was created\n",
        "!find /content/soh-ml/DATA -maxdepth 1"
      ],
      "metadata": {
        "id": "5wJNGzC-Aq1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b41c59-e44f-48cb-f8e2-cea63592d9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/soh-ml/DATA\n",
            "/content/soh-ml/DATA/dataset_v5_ts_npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs, imports, fix seed"
      ],
      "metadata": {
        "id": "ghJT75xPK-0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run cell below to install packages"
      ],
      "metadata": {
        "id": "4jEk3v6ULUdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "POTENTIAL FUTURE PROBLEMS WITH REPRODUCIBILITY\n",
        "here should be pip install from requirements_colab for reproducibility\n",
        "but now it results in errors :/\n",
        "!pip install -r requirements_colab.txt -q\n",
        "\"\"\"\n",
        "\n",
        "!pip install tensorboard tbparse pytorch-lightning lightning -q"
      ],
      "metadata": {
        "id": "fBb_4rjuOYqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make sure that you are in project directory content/soh-ml, otherwise some imports will fail"
      ],
      "metadata": {
        "id": "JJPxJvmRLVnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/soh-ml/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGlZz2xQ34jX",
        "outputId": "30106b5b-9620-4ac0-e56c-9438e7f3c993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/soh-ml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "make imports, fix seed"
      ],
      "metadata": {
        "id": "hiaWRQpVLo8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import learning\n",
        "import cross_validation\n",
        "\n",
        "from lightning import seed_everything\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX75gBYmx6az",
        "outputId": "1e3342d8-b748-4fb0-fb62-eb349941231a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running single experiments"
      ],
      "metadata": {
        "id": "jEU6KZi7Lt41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## how to"
      ],
      "metadata": {
        "id": "yxEI0g1zROkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "you can use run_experiment function from learning.py to run experiment. \\\n",
        "This will run experiment with default testing configuration:\n",
        "```python\n",
        "learning.run_experiment(learning.test_config)\n",
        "```\n",
        "Also, you can run it from command line. Without arguments it will run with test_config configuration:\n",
        "```bash\n",
        "!python learning.py\n",
        "```"
      ],
      "metadata": {
        "id": "vBvwqog7LzHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run experiment with your own config, you can specify it using python code and then pass config dictionary as argument to run_experiment function:\n",
        "```python\n",
        "# all keys (except ['test'] in ['data'])\n",
        "# shoud be present in this single experiment configure dictionary:\n",
        "my_config = {\n",
        "    'experiment_name': 'my_experiment', # also used for TensorBoard logging\n",
        "    'seed': 42,\n",
        "\n",
        "    'data': {\n",
        "        'datadir':'./DATA/dataset_v5_ts_npz/',\n",
        "        # 'supported subsets as string arguments:\n",
        "        # 'blacklist', 'small', 'train', 'val', 'test'\n",
        "        # or you can specify subset using list with battery IDs\n",
        "        'train': 'train',\n",
        "        'val': 'val',\n",
        "        #'test': None # normally, you dont need to specify test dataset\n",
        "        # supported normalization types:\n",
        "        # 'minmax_zero_one', 'minmax_symmetric', 'meanimax', 'meanstd'\n",
        "        'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "        'n_diff': 0,\n",
        "    },\n",
        "\n",
        "    'model': {\n",
        "        'input_size': 2,\n",
        "        'cnn_hidden_dim': 32,\n",
        "        'cnn_channels': [4, 8, 16],\n",
        "        'lstm_hidden_size': 32,\n",
        "        'num_layers': 1,\n",
        "        'output_size': 1, # do not change that\n",
        "        'dropout': 0.,\n",
        "        'regressor_hidden_dim': 1024,\n",
        "        'output_activation': 'sigmoid', # 'tanh', 'sigmoid', 'relu' are supported\n",
        "    },\n",
        "\n",
        "    'training': {\n",
        "        # resume_ckpt supported options:\n",
        "        # None, 'auto', 'from_best', 'from_last' or path to .ckpt file\n",
        "        # aware of using checkpoints when it is not applicable,\n",
        "        # i.e. model has changed\n",
        "        'resume_ckpt': 'from_last',\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 1e-3,\n",
        "        'loss_type': 'huber1.0', # 'mse', 'mae, 'huberX.X', 'bce' are supported\n",
        "        'epochs': 1,\n",
        "        'accelerator': 'auto',\n",
        "        'devices': 1,\n",
        "    },\n",
        "\n",
        "    'metrics': 'all', # 'all', 'mse', 'mae', 'mape', 'r2', 'pcc' are supported\n",
        "\n",
        "    'logging': {\n",
        "        # change logging directory\n",
        "        # so you wouldnt waste logs when runtime would be killed\n",
        "        # /content/drive/MyDrive/for-soh-ml/LOGS\n",
        "        'log_dir': './LOGS',\n",
        "        'progress_bar': True,\n",
        "        'plot': True,\n",
        "        'savefig': True,\n",
        "    }\n",
        "}\n",
        "```\n",
        "and then run experiment just like this:\n",
        "```python\n",
        "learning.run_experiment(my_config)\n",
        "```\n",
        "also, such config may be stored in .yaml format and then you can pass it to run_experiment:\n",
        "```python\n",
        "learning.run_experiment('path/to/my/config/my_config.yaml')\n",
        "```\n",
        "also you can specify config when running learning.py in command line:\n",
        "```bash\n",
        "!python learning.py --config path/to/my/config.yaml\n",
        "```"
      ],
      "metadata": {
        "id": "E6hrPk70Nkjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "during experiment, inside LOGS directory (or any other 'log_dir', which you will specify in config) \\\n",
        "would be created directory for each experiment and version: \\\n",
        "my_experiment/version_0"
      ],
      "metadata": {
        "id": "iV5BGQOsSQ7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "aKzJ8GrAXLFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/for-soh-ml/LOGS --port=5005"
      ],
      "metadata": {
        "id": "J7Hs1w4dXusK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on small, validate on train"
      ],
      "metadata": {
        "id": "rCvlz4rjXcwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all keys (except ['test'] in ['data'])\n",
        "# shoud be present in this single experiment configure dictionary:\n",
        "tr_small_val_train_config_128 = {\n",
        "    'experiment_name': 'tr_small_val_train_128', # also used for TensorBoard logging\n",
        "    'seed': 42,\n",
        "\n",
        "    'data': {\n",
        "        'datadir':'./DATA/dataset_v5_ts_npz/',\n",
        "        # 'supported subsets as string arguments:\n",
        "        # 'blacklist', 'small', 'train', 'val', 'test'\n",
        "        # or you can specify subset using list with battery IDs\n",
        "        'train': 'small',\n",
        "        'val': 'train',\n",
        "        #'test': None # normally, you dont need to specify test dataset\n",
        "        # supported normalization types:\n",
        "        # 'minmax_zero_one', 'minmax_symmetric', 'meanimax', 'meanstd'\n",
        "        'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "        'n_diff': 0,\n",
        "    },\n",
        "\n",
        "    'model': {\n",
        "        'input_size': 2,\n",
        "        'cnn_hidden_dim': 32,\n",
        "        'cnn_channels': [4, 8, 16],\n",
        "        'lstm_hidden_size': 32,\n",
        "        'num_layers': 1,\n",
        "        'output_size': 1, # do not change that\n",
        "        'dropout': 0.,\n",
        "        'regressor_hidden_dim': 128,\n",
        "        'output_activation': 'sigmoid', # 'tanh', 'sigmoid', 'relu' are supported\n",
        "    },\n",
        "\n",
        "    'training': {\n",
        "        # resume_ckpt supported options:\n",
        "        # None, 'auto', 'from_best', 'from_last' or path to .ckpt file\n",
        "        # aware of using checkpoints when it is not applicable,\n",
        "        # i.e. model has changed\n",
        "        'resume_ckpt': 'from_last',\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 1e-3,\n",
        "        'loss_type': 'huber1.0', # 'mse', 'mae, 'huberX.X', 'bce' are supported\n",
        "        'epochs': 250,\n",
        "        'accelerator': 'auto',\n",
        "        'devices': 1,\n",
        "    },\n",
        "\n",
        "    'metrics': 'all', # 'all', 'mse', 'mae', 'mape', 'r2', 'pcc' are supported\n",
        "\n",
        "    'logging': {\n",
        "        # change logging directory\n",
        "        # so you wouldnt waste logs when runtime would be killed\n",
        "        # /content/drive/MyDrive/for-soh-ml/LOGS\n",
        "        'log_dir': '/content/drive/MyDrive/for-soh-ml/LOGS',\n",
        "        'progress_bar': True,\n",
        "        'plot': True,\n",
        "        'savefig': True,\n",
        "    }\n",
        "}\n",
        "\n",
        "learning.run_experiment(tr_small_val_train_config_128)"
      ],
      "metadata": {
        "id": "JhZ4CKxkKX0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all keys (except ['test'] in ['data'])\n",
        "# shoud be present in this single experiment configure dictionary:\n",
        "tr_small_val_train_config_256 = {\n",
        "    'experiment_name': 'tr_small_val_train_256', # also used for TensorBoard logging\n",
        "    'seed': 42,\n",
        "\n",
        "    'data': {\n",
        "        'datadir':'./DATA/dataset_v5_ts_npz/',\n",
        "        # 'supported subsets as string arguments:\n",
        "        # 'blacklist', 'small', 'train', 'val', 'test'\n",
        "        # or you can specify subset using list with battery IDs\n",
        "        'train': 'small',\n",
        "        'val': 'train',\n",
        "        #'test': None # normally, you dont need to specify test dataset\n",
        "        # supported normalization types:\n",
        "        # 'minmax_zero_one', 'minmax_symmetric', 'meanimax', 'meanstd'\n",
        "        'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "        'n_diff': 0,\n",
        "    },\n",
        "\n",
        "    'model': {\n",
        "        'input_size': 2,\n",
        "        'cnn_hidden_dim': 32,\n",
        "        'cnn_channels': [4, 8, 16],\n",
        "        'lstm_hidden_size': 32,\n",
        "        'num_layers': 1,\n",
        "        'output_size': 1, # do not change that\n",
        "        'dropout': 0.,\n",
        "        'regressor_hidden_dim': 256,\n",
        "        'output_activation': 'sigmoid', # 'tanh', 'sigmoid', 'relu' are supported\n",
        "    },\n",
        "\n",
        "    'training': {\n",
        "        # resume_ckpt supported options:\n",
        "        # None, 'auto', 'from_best', 'from_last' or path to .ckpt file\n",
        "        # aware of using checkpoints when it is not applicable,\n",
        "        # i.e. model has changed\n",
        "        'resume_ckpt': 'from_last',\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 1e-3,\n",
        "        'loss_type': 'huber1.0', # 'mse', 'mae, 'huberX.X', 'bce' are supported\n",
        "        'epochs': 250,\n",
        "        'accelerator': 'auto',\n",
        "        'devices': 1,\n",
        "    },\n",
        "\n",
        "    'metrics': 'all', # 'all', 'mse', 'mae', 'mape', 'r2', 'pcc' are supported\n",
        "\n",
        "    'logging': {\n",
        "        # change logging directory\n",
        "        # so you wouldnt waste logs when runtime would be killed\n",
        "        # /content/drive/MyDrive/for-soh-ml/LOGS\n",
        "        'log_dir': '/content/drive/MyDrive/for-soh-ml/LOGS',\n",
        "        'progress_bar': True,\n",
        "        'plot': True,\n",
        "        'savefig': True,\n",
        "    }\n",
        "}\n",
        "\n",
        "learning.run_experiment(tr_small_val_train_config_256)"
      ],
      "metadata": {
        "id": "STisKDuFnxud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running cross-validation"
      ],
      "metadata": {
        "id": "glD9U8A364fI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## how to"
      ],
      "metadata": {
        "id": "nBmowOmp_8E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of master cross-validation config:\n",
        "\n",
        "```python\n",
        "cv_experiment_config = {\n",
        "    'master_name': 'cv_experiment_config',\n",
        "    'base_config': {\n",
        "        'experiment_name': None,\n",
        "        'seed': 42,\n",
        "        'data': {\n",
        "            'datadir': './DATA/dataset_v5_ts_npz/',\n",
        "            'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "            'n_diff': 0,\n",
        "        },\n",
        "        'model': {\n",
        "            'input_size': 2,\n",
        "            'cnn_hidden_dim': 32,\n",
        "            'cnn_channels': [4, 8, 16],\n",
        "            'lstm_hidden_size': 32,\n",
        "            'num_layers': 1,\n",
        "            'output_size': 1,\n",
        "            'dropout': 0.,\n",
        "            'regressor_hidden_dim': 1024,\n",
        "            'output_activation': 'sigmoid',\n",
        "        },\n",
        "        'training': {\n",
        "            'resume_ckpt': None,\n",
        "            'batch_size': 32,\n",
        "            'learning_rate': 1e-3,\n",
        "            'loss_type': 'huber1.0',\n",
        "            'epochs': 2,\n",
        "            'accelerator': 'auto',\n",
        "            'devices': 1,\n",
        "        },\n",
        "        'metrics': 'all',\n",
        "        'logging': {\n",
        "            # to MyDrive:\n",
        "            'log_dir': '/content/drive/MyDrive/for-soh-ml/LOGS/cross-validation/',\n",
        "            'progress_bar': True,\n",
        "            'plot': False,\n",
        "            'savefig': True,\n",
        "        }\n",
        "    },\n",
        "    'hyperparam_grid': {\n",
        "        'model': {\n",
        "            'cnn_hidden_dim': [16, 32],\n",
        "        },\n",
        "    },\n",
        "    'crossval_settings': {\n",
        "        'n_splits': 2,\n",
        "        'method': 'stratified', # 'regular' or 'stratified'\n",
        "        'strat_label': 'chem', # should be None if 'method' == 'regular'\n",
        "        'dataset_subset': 'small',\n",
        "    }\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "ip5UvON5_-T7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "you can run cross validation from command line \\\n",
        "(without any arguments it will run with test config):\n",
        "```\n",
        "!python cross_validation.py\n",
        "```\n",
        "or specify master cross validation config in .yaml file:\n",
        "```\n",
        "!python cross_validation.py --config path/to/master/cv/config.yaml\n",
        "```"
      ],
      "metadata": {
        "id": "U7odSbzeBTQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "and ofcourse you can run it using python code. \\\n",
        "you can specify config as python dictionary:\n",
        "```python\n",
        "validator = cross_validation.CrossValidator(cv_experiment_config)\n",
        "```\n",
        "\n",
        "or you can specify path to config in .yaml:\n",
        "```python\n",
        "validator = cross_validation.CrossValidator('path/to/master/cv/config.yaml')\n",
        "```\n",
        "\n",
        "then you have to run validation just by .run() method:\n",
        "```python\n",
        "validator.run()\n",
        "```"
      ],
      "metadata": {
        "id": "Mk0eYm0bCDbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "IePmzLVjEVUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "91hC8apHF728"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/soh-ml/LOGS/cross-validation/cv_test --port=7007"
      ],
      "metadata": {
        "id": "EUFi01OaEb-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_test_config = {\n",
        "    'master_name': 'cv_test',\n",
        "    'base_config': {\n",
        "        'experiment_name': None,\n",
        "        'seed': 42,\n",
        "        'data': {\n",
        "            'datadir': './DATA/dataset_v5_ts_npz/',\n",
        "            'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "            'n_diff': 0,\n",
        "        },\n",
        "        'model': {\n",
        "            'input_size': 2,\n",
        "            'cnn_hidden_dim': 32,\n",
        "            'cnn_channels': [4, 8, 16],\n",
        "            'lstm_hidden_size': 32,\n",
        "            'num_layers': 1,\n",
        "            'output_size': 1,\n",
        "            'dropout': 0.,\n",
        "            'regressor_hidden_dim': 1024,\n",
        "            'output_activation': 'sigmoid',\n",
        "        },\n",
        "        'training': {\n",
        "            'resume_ckpt': None,\n",
        "            'batch_size': 32,\n",
        "            'learning_rate': 1e-3,\n",
        "            'loss_type': 'huber1.0',\n",
        "            'epochs': 2,\n",
        "            'accelerator': 'auto',\n",
        "            'devices': 1,\n",
        "        },\n",
        "        'metrics': 'all',\n",
        "        'logging': {\n",
        "            # to MyDrive:\n",
        "            #'log_dir': '/content/drive/MyDrive/for-soh-ml/LOGS/cross-validation/',\n",
        "            'log_dir': '/content/soh-ml/LOGS/cross-validation/',\n",
        "            'progress_bar': True,\n",
        "            'plot': False,\n",
        "            'savefig': True,\n",
        "        }\n",
        "    },\n",
        "    'hyperparam_grid': {\n",
        "        'model': {\n",
        "            'cnn_hidden_dim': [16, 32],\n",
        "        },\n",
        "    },\n",
        "    'crossval_settings': {\n",
        "        'n_splits': 2,\n",
        "        'method': 'stratified', # 'regular' or 'stratified'\n",
        "        'strat_label': 'chem', # should be None if 'method' == 'regular'\n",
        "        'dataset_subset': 'small',\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "hv5N-Ssw7Io6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validator = cross_validation.CrossValidator(cv_test_config)"
      ],
      "metadata": {
        "id": "ib_8LRkmD4nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validator.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlgOcbsyEB2x",
        "outputId": "5e8fef98-3e20-4bd8-ea4c-9efccf06dd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping completed experiment: 29b413e0_fold_0\n",
            "Skipping completed experiment: 29b413e0_fold_1\n",
            "Skipping completed experiment: 0f9db9ac_fold_0\n",
            "Skipping completed experiment: 0f9db9ac_fold_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validator._generate_param_combinations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA-reXNbsYFZ",
        "outputId": "c7abef02-fa90-4248-9b77-254740b436c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'model': {'cnn_hidden_dim': 16}}, {'model': {'cnn_hidden_dim': 32}}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cv1_small"
      ],
      "metadata": {
        "id": "erXUp5dRF-c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/soh-ml/LOGS/cross-validation/cv1_small --port=2003"
      ],
      "metadata": {
        "id": "cI9K0dp0GY9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv1_small_config = {\n",
        "    'master_name': 'cv1_small',\n",
        "    'base_config': {\n",
        "        'experiment_name': None,\n",
        "        'seed': 42,\n",
        "        'data': {\n",
        "            'datadir': './DATA/dataset_v5_ts_npz/',\n",
        "            'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "            'n_diff': 0,\n",
        "        },\n",
        "        'model': {\n",
        "            'input_size': 2,\n",
        "            'cnn_hidden_dim': 32,\n",
        "            'cnn_channels': [4, 8, 16],\n",
        "            'lstm_hidden_size': 32,\n",
        "            'num_layers': 1,\n",
        "            'output_size': 1,\n",
        "            'dropout': 0.,\n",
        "            'regressor_hidden_dim': 128,\n",
        "            'output_activation': 'sigmoid',\n",
        "        },\n",
        "        'training': {\n",
        "            'resume_ckpt': None,\n",
        "            'batch_size': 32,\n",
        "            'learning_rate': 1e-3,\n",
        "            'loss_type': 'huber1.0',\n",
        "            'epochs': 50,\n",
        "            'accelerator': 'auto',\n",
        "            'devices': 1,\n",
        "        },\n",
        "        'metrics': 'all',\n",
        "        'logging': {\n",
        "            # to MyDrive:\n",
        "            #'log_dir': '/content/drive/MyDrive/for-soh-ml/LOGS/cross-validation/',\n",
        "            'log_dir': '/content/soh-ml/LOGS/cross-validation/',\n",
        "            'progress_bar': True,\n",
        "            'plot': False,\n",
        "            'savefig': True,\n",
        "        }\n",
        "    },\n",
        "    'hyperparam_grid': {\n",
        "        'model': {\n",
        "            'dropout': [0.0, 0.25],\n",
        "        },\n",
        "    },\n",
        "    'crossval_settings': {\n",
        "        'n_splits': 4,\n",
        "        'method': 'stratified', # 'regular' or 'stratified'\n",
        "        'strat_label': 'chem', # should be None if 'method' == 'regular'\n",
        "        'dataset_subset': 'small',\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "eFvyGJspF_07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validator_1_small = cross_validation.CrossValidator(cv1_small_config)"
      ],
      "metadata": {
        "id": "Xpg6focyJedx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validator_1_small.run()"
      ],
      "metadata": {
        "id": "tOmf-h_AJfzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r \"{temp_dir}/\" \"{drive_dir}/\"\n",
        "!cp -r /content/soh-ml/LOGS/cross-validation/cv1_small /content/drive/MyDrive/for-soh-ml/LOGS/cross-validation/cv1_small"
      ],
      "metadata": {
        "id": "uM6HX8S7zXdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cv2_small"
      ],
      "metadata": {
        "id": "i75anAfLv6-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/soh-ml/LOGS/cross-validation/cv2_small --port=3002"
      ],
      "metadata": {
        "id": "j2ZFC9Dfv8P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_small_config = {\n",
        "    'master_name': 'cv2_small',\n",
        "    'base_config': {\n",
        "        'experiment_name': None,\n",
        "        'seed': 42,\n",
        "        'data': {\n",
        "            'datadir': './DATA/dataset_v5_ts_npz/',\n",
        "            'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "            'n_diff': 0,\n",
        "        },\n",
        "        'model': {\n",
        "            'input_size': 2,\n",
        "            'cnn_hidden_dim': 32,\n",
        "            'cnn_channels': [4, 8, 16],\n",
        "            'lstm_hidden_size': 32,\n",
        "            'num_layers': 1,\n",
        "            'output_size': 1,\n",
        "            'dropout': 0.,\n",
        "            'regressor_hidden_dim': 128,\n",
        "            'output_activation': 'sigmoid',\n",
        "        },\n",
        "        'training': {\n",
        "            'resume_ckpt': None,\n",
        "            'batch_size': 32,\n",
        "            'learning_rate': 1e-3,\n",
        "            'loss_type': 'huber1.0',\n",
        "            'epochs': 150,\n",
        "            'accelerator': 'auto',\n",
        "            'devices': 1,\n",
        "        },\n",
        "        'metrics': 'all',\n",
        "        'logging': {\n",
        "            # to MyDrive:\n",
        "            #'log_dir': '/content/drive/MyDrive/for-soh-ml/LOGS/cross-validation/',\n",
        "            'log_dir': '/content/soh-ml/LOGS/cross-validation/',\n",
        "            'progress_bar': True,\n",
        "            'plot': False,\n",
        "            'savefig': True,\n",
        "        }\n",
        "    },\n",
        "    'hyperparam_grid': {\n",
        "        'model': {\n",
        "            'dropout': [0.0, 0.25],\n",
        "        },\n",
        "    },\n",
        "    'crossval_settings': {\n",
        "        'n_splits': 4,\n",
        "        'method': 'stratified', # 'regular' or 'stratified'\n",
        "        'strat_label': 'chem', # should be None if 'method' == 'regular'\n",
        "        'dataset_subset': 'small',\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "fzV4PbuNvfby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validator_2_small = cross_validation.CrossValidator(cv2_small_config)"
      ],
      "metadata": {
        "id": "3-oZvUYav51Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validator_2_small.run()"
      ],
      "metadata": {
        "id": "fxQctbKOwP49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r \"{temp_dir}/\" \"{drive_dir}/\"\n",
        "!cp -r /content/soh-ml/LOGS/cross-validation/cv2_small /content/drive/MyDrive/for-soh-ml/LOGS/cross-validation/cv2_small"
      ],
      "metadata": {
        "id": "x9fT4rhKwTOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cv3_small"
      ],
      "metadata": {
        "id": "u7Ick94A1zqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/soh-ml/LOGS/cross-validation/cv3_small --port=4003"
      ],
      "metadata": {
        "id": "rhwjoeYT2Hn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv3_small_config = {\n",
        "    'master_name': 'cv3_small',\n",
        "    'base_config': {\n",
        "        'experiment_name': None,\n",
        "        'seed': 42,\n",
        "        'data': {\n",
        "            'datadir': './DATA/dataset_v5_ts_npz/',\n",
        "            'normalization': {'x': None, 'y': 'minmax_zero_one'},\n",
        "            'n_diff': 0,\n",
        "        },\n",
        "        'model': {\n",
        "            'input_size': 2,\n",
        "            'cnn_hidden_dim': 32,\n",
        "            'cnn_channels': [4, 8, 16],\n",
        "            'lstm_hidden_size': 32,\n",
        "            'num_layers': 1,\n",
        "            'output_size': 1,\n",
        "            'dropout': 0.,\n",
        "            'regressor_hidden_dim': 128,\n",
        "            'output_activation': 'sigmoid',\n",
        "        },\n",
        "        'training': {\n",
        "            'resume_ckpt': None,\n",
        "            'batch_size': 32,\n",
        "            'learning_rate': 1e-3,\n",
        "            'loss_type': 'huber1.0',\n",
        "            'epochs': 150,\n",
        "            'accelerator': 'auto',\n",
        "            'devices': 1,\n",
        "        },\n",
        "        'metrics': 'all',\n",
        "        'logging': {\n",
        "            # to MyDrive:\n",
        "            #'log_dir': '/content/drive/MyDrive/for-soh-ml/LOGS/cross-validation/',\n",
        "            'log_dir': '/content/soh-ml/LOGS/cross-validation/',\n",
        "            'progress_bar': True,\n",
        "            'plot': False,\n",
        "            'savefig': True,\n",
        "        }\n",
        "    },\n",
        "    'hyperparam_grid': {\n",
        "        'data':{\n",
        "            'normalization': [\n",
        "                {'x': None, 'y': 'minmax_zero_one'},\n",
        "                {'x': 'meanimax', 'y': 'minmax_zero_one'},\n",
        "            ],\n",
        "            'n_diff': [0, 1],\n",
        "        },\n",
        "    },\n",
        "    'crossval_settings': {\n",
        "        'n_splits': 4,\n",
        "        'method': 'stratified', # 'regular' or 'stratified'\n",
        "        'strat_label': 'chem', # should be None if 'method' == 'regular'\n",
        "        'dataset_subset': 'small',\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "ijjSQg-b1zGV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}